{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSDS 696: Practicum II\n",
    "## Emma Highland\n",
    "\n",
    "## Introduction\n",
    "This project uses the [MovieLens 100k Dataset](https://grouplens.org/datasets/movielens/100k/). Below I have included the citation for this data set.\n",
    "\n",
    "> F. Maxwell Harper and Joseph A. Konstan. 2015. The MovieLens Datasets:\n",
    "History and Context. ACM Transactions on Interactive Intelligent\n",
    "Systems (TiiS) 5, 4, Article 19 (December 2015), 19 pages.\n",
    "DOI=http://dx.doi.org/10.1145/2827872\n",
    "\n",
    "For this project, I performed exploratory data analysis and data cleaning in R (see associated .Rmd file). One step I took was to limit the genres included, using only genres that appeared a minimum of 10,000 times. Because individual movies are classified into multiple genres, this did not eliminate any movies. I chose to eliminate some more rare genres in order to obtain unique results, as I planned to follow a tutorial that used all data.\n",
    "\n",
    "In this notebook, I use the K-Nearest Neighbors algorithm for two different purposes. First, I implement a KNN approach to suggest movies based on a given movie as a reference point. For this step, I follow the example of M. Hendra Herviawan, available for your consideration at [this link](https://hendra-herviawan.github.io/Movie-Recommendation-based-on-KNN-K-Nearest-Neighbors.html). Second, I implement a KNN approach using the library scikit-learn. The purpose of this second use of KNN was to predict genre from ratings. \n",
    "\n",
    "Overall, my goal is to examine the recommendations and consider how the different features of the dataset might inform the recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import needed libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import operator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and manipulate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie.ID</th>\n",
       "      <th>Movie.Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>242</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>302</td>\n",
       "      <td>L.A. Confidential (1997)</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>377</td>\n",
       "      <td>Heavyweights (1994)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51</td>\n",
       "      <td>Legends of the Fall (1994)</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>346</td>\n",
       "      <td>Jackie Brown (1997)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>474</td>\n",
       "      <td>Dr. Strangelove or: How I Learned to Stop Worr...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>265</td>\n",
       "      <td>Hunt for Red October, The (1990)</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>465</td>\n",
       "      <td>Jungle Book, The (1994)</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>451</td>\n",
       "      <td>Grease (1978)</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>86</td>\n",
       "      <td>Remains of the Day, The (1993)</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>257</td>\n",
       "      <td>Men in Black (1997)</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1014</td>\n",
       "      <td>Romy and Michele's High School Reunion (1997)</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>222</td>\n",
       "      <td>Star Trek: First Contact (1996)</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>40</td>\n",
       "      <td>To Wong Foo, Thanks for Everything! Julie Newm...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>29</td>\n",
       "      <td>Batman Forever (1995)</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Movie.ID                                        Movie.Title  Rating  \\\n",
       "0        242                                       Kolya (1996)       3   \n",
       "1        302                           L.A. Confidential (1997)       3   \n",
       "2        377                                Heavyweights (1994)       1   \n",
       "3         51                         Legends of the Fall (1994)       2   \n",
       "4        346                                Jackie Brown (1997)       1   \n",
       "5        474  Dr. Strangelove or: How I Learned to Stop Worr...       4   \n",
       "6        265                   Hunt for Red October, The (1990)       2   \n",
       "7        465                            Jungle Book, The (1994)       5   \n",
       "8        451                                      Grease (1978)       3   \n",
       "9         86                     Remains of the Day, The (1993)       3   \n",
       "10       257                                Men in Black (1997)       2   \n",
       "11      1014      Romy and Michele's High School Reunion (1997)       5   \n",
       "12       222                    Star Trek: First Contact (1996)       5   \n",
       "13        40  To Wong Foo, Thanks for Everything! Julie Newm...       3   \n",
       "14        29                              Batman Forever (1995)       3   \n",
       "\n",
       "    Action  Adventure  Comedy  Drama  Romance  Sci-Fi  Thriller  \n",
       "0        0          0       1      0        0       0         0  \n",
       "1        0          0       0      0        0       0         1  \n",
       "2        0          0       1      0        0       0         0  \n",
       "3        0          0       0      1        1       0         0  \n",
       "4        0          0       0      1        0       0         0  \n",
       "5        0          0       0      0        0       1         0  \n",
       "6        1          0       0      0        0       0         1  \n",
       "7        0          1       0      0        1       0         0  \n",
       "8        0          0       1      0        1       0         0  \n",
       "9        0          0       0      1        0       0         0  \n",
       "10       1          1       1      0        0       1         0  \n",
       "11       0          0       1      0        0       0         0  \n",
       "12       1          1       0      0        0       1         0  \n",
       "13       0          0       1      0        0       0         0  \n",
       "14       1          1       1      0        0       0         0  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the first 15 rows of the imported Pandas data frame\n",
    "movieDF = pd.read_csv('movie_new.csv', encoding='latin-1',usecols=range(1,11))\n",
    "movieDF.head(n=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Rating</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Movie.ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>452</td>\n",
       "      <td>3.878319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>131</td>\n",
       "      <td>3.206107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90</td>\n",
       "      <td>3.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>209</td>\n",
       "      <td>3.550239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>86</td>\n",
       "      <td>3.302326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Rating          \n",
       "           size      mean\n",
       "Movie.ID                 \n",
       "1           452  3.878319\n",
       "2           131  3.206107\n",
       "3            90  3.033333\n",
       "4           209  3.550239\n",
       "5            86  3.302326"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Following the example of M. Hendra Herviawan\n",
    "# https://hendra-herviawan.github.io/Movie-Recommendation-based-on-KNN-K-Nearest-Neighbors.html\n",
    "# Comments by me\n",
    "\n",
    "movieStats = movieDF.groupby('Movie.ID').agg({'Rating': [np.size, np.mean]})\n",
    "''' \n",
    "Group the movies according to ID (movies appear multiple times in data), then\n",
    "aggregate the 'Rating' feature according to both the \"size\" (i.e. amount of\n",
    "occurences) and the mean rating. Aggregation is done using numpy.\n",
    "'''\n",
    "movieStats.head() # View the first 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Movie.ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.774914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.223368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.152921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.357388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.146048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              size\n",
       "Movie.ID          \n",
       "1         0.774914\n",
       "2         0.223368\n",
       "3         0.152921\n",
       "4         0.357388\n",
       "5         0.146048"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Following the example of M. Hendra Herviawan\n",
    "# https://hendra-herviawan.github.io/Movie-Recommendation-based-on-KNN-K-Nearest-Neighbors.html\n",
    "# Comments by me\n",
    "\n",
    "m = pd.DataFrame(movieStats['Rating']['size'])\n",
    "# Save the size feature to a new variable, m\n",
    "mNorm = m.apply(lambda x: (x - np.min(x)) / (np.max(x) - np.min(x)))\n",
    "''' \n",
    "Normalize the sizes to represent relative abudance of each movie.\n",
    "The scale is 0 to 1. As worded by Herviawan, \"a value of 0 means \n",
    "nobody rated it, and a value of 1 will mean it's the most popular \n",
    "movie there is.\"\n",
    "Normalization is accomplished via applying lambda function that \n",
    "uses the normalization formula on the items in m.\n",
    "'''\n",
    "mNorm.head() # View the first 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movieDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dictionary \n",
    "\n",
    "Now that the data has been manipulated, I will use the normalized data and the original Pandas data frame to create a dictionary. Because I had already done data cleaning in R, I had to follow a different procedure to create the dictionary than that presented by Herviawan. That said, the idea is the same. I created a dictionary that uses the movie ID as a key and that movie's title, genre list, relative abundance, and mean rating as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movieDict = {}\n",
    "for i in range(len(movieDF)):\n",
    "    name = movieDF['Movie.Title'][i]\n",
    "    ID = movieDF['Movie.ID'][i]\n",
    "    genre = [movieDF[x][i] for x in ['Action','Adventure','Comedy','Drama','Romance','Sci-Fi','Thriller']]\n",
    "    movieDict[ID] = (name, genre, mNorm.loc[ID].get('size'), movieStats.loc[ID].Rating.get('mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Toy Story (1995)', [0, 0, 1, 0, 0, 0, 0], 0.7749140893470791, 3.8783185840707963)\n"
     ]
    }
   ],
   "source": [
    "print(movieDict[1])\n",
    "# The movie with the ID 1 is Toy Story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Men in Black (1997)', [1, 1, 1, 0, 0, 1, 0], 0.5189003436426117, 3.745874587458746)\n"
     ]
    }
   ],
   "source": [
    "print(movieDict[257])\n",
    "# The movie with the ID 257 is Men in Black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN for Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ComputeDistance() Function\n",
    "\n",
    "I used the following two functions from Herviawan's tutorial. The first computes distance between two movies based on genre - using cosine similarity - and the difference in relative abundance. The second computes the 10 nearest neighbors using the previous function. I have added commentary to both functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code from M. Hendra Herviawan\n",
    "# https://hendra-herviawan.github.io/Movie-Recommendation-based-on-KNN-K-Nearest-Neighbors.html\n",
    "# Comments by me\n",
    "\n",
    "def ComputeDistance(a, b):\n",
    "    genresA = a[1] # grab the genre list from the first input movie\n",
    "    genresB = b[1] # grab the genre list from the second input movie\n",
    "    genreDistance = spatial.distance.cosine(genresA, genresB)\n",
    "    '''\n",
    "    Compute the cosine similarity to find distance between two movies.\n",
    "    Cosine similarity finds distance via computing the cosine of the\n",
    "    angle between two vectors. Here, those two vectors are the lists \n",
    "    of genres. Although the genre lists are of the same length, cosine\n",
    "    similarity is effective for vectors of different sizes as well.\n",
    "    '''\n",
    "    popularityA = a[2] # grab the popularity/relative abundance from a\n",
    "    popularityB = b[2] # grab this information from b\n",
    "    popularityDistance = abs(popularityA - popularityB)\n",
    "    # Take the absolute value of the difference between a and b\n",
    "    return genreDistance + popularityDistance\n",
    "    # Return the distance as defined by both genre and relative abundance  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7560137457044673"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ComputeDistance(movieDict[1], movieDict[257])\n",
    "# Compute the distance between Toy Story and Men in Black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As noted by Herviawan, \"the higher the distance, the less similar the movies are\" and I would classify 0.75 to mean the movies are moderately different. I chose these two movies because they are both popular, family-friendly, action or adventure movies of the 1990s that launched franchises. I want to quickly remind the reader that a correlation chart was produced with R's PredictiveAnalytics library in the data exploration and cleaning phase. The highest correlation exists between action and adventure. Thus, the link between action and adventure movies is supported by the data.\n",
    "\n",
    "Nota bene that some of my proposed similarities are not actually represented by the data. The algorithm *does not* consider that they came out only two years apart or care about their cultural significance. The algorithm *does* take into account the popularity (as defined by relative abundance) and genre. In this case, my concept of the genres for Toy Story would be adventure and comedy. However, it is placed only in the comedy category here. It would also belong in the 'Children' and 'Animation' categories, and does in the full dataset. It will be interesting to see what difference narrowing the genres makes. Although Toy Story is shown to be a popular movie, there is more limited data to distinguish it from other movies. Of course, the absence of categories could also distinguish it if most movies are still in multiple categories. Men in Black is placed in both, which is how I could classify it. It is also counted as Sci-Fi and a Comedy, categorizations with which I agree. Men in Black could very well be easier to find recomendations for than Toy Story.\n",
    "\n",
    "Next, a function for KNN will be defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### getNeighbors() Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Toy Story (1995)', [0, 0, 1, 0, 0, 0, 0], 0.7749140893470791, 3.8783185840707963) \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emma/anaconda3/lib/python3.6/site-packages/scipy/spatial/distance.py:720: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sting, The (1973) 4.058091286307054\n",
      "Aladdin (1992) 3.8127853881278537\n",
      "Mary Poppins (1964) 3.7247191011235956\n",
      "Father of the Bride Part II (1995) 2.8984375\n",
      "Kolya (1996) 3.9914529914529915\n",
      "Romy and Michele's High School Reunion (1997) 3.061224489795918\n",
      "Cool Runnings (1993) 3.161764705882353\n",
      "To Wong Foo, Thanks for Everything! Julie Newmar (1995) 2.8947368421052633\n",
      "Sleepless in Seattle (1993) 3.539906103286385\n",
      "Bio-Dome (1996) 1.903225806451613\n"
     ]
    }
   ],
   "source": [
    "# Code from M. Hendra Herviawan\n",
    "# https://hendra-herviawan.github.io/Movie-Recommendation-based-on-KNN-K-Nearest-Neighbors.html\n",
    "# Comments by me\n",
    "def getNeighbors(movieID, K):\n",
    "    distances = [] # Empty list to hold the distances\n",
    "    for movie in movieDict:\n",
    "        if (movie != movieID):\n",
    "            dist = ComputeDistance(movieDict[movieID], movieDict[movie])\n",
    "            distances.append((movie, dist))\n",
    "    ''' \n",
    "    This for loop iterates through each key in movieDict.\n",
    "    In each iteration, the key is assigned to the variable 'movie'\n",
    "    If 'movie' is not being compared to itself (movie != movieID),\n",
    "    the cosine similarity and popularity difference are computed.\n",
    "    This means every movie is compared to every other movie. \n",
    "    At each comparison, the distance is assigned to the variable 'dist'\n",
    "    and the empty list 'distances' stores this variable.\n",
    "    '''\n",
    "    distances.sort(key=operator.itemgetter(1))\n",
    "    neighbors = []\n",
    "    for x in range(K):\n",
    "        neighbors.append(distances[x][0])\n",
    "    return neighbors\n",
    "'''\n",
    "Sort the distances (index of 1 in the 'distances' list) in \n",
    "descending order (the default) and then define an empty list\n",
    "for the neighbors. Then populate the empty list with the first\n",
    "10 items in 'distances'.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Toy Story (1995)', [0, 0, 1, 0, 0, 0, 0], 0.7749140893470791, 3.8783185840707963) \n",
      "\n",
      "Sting, The (1973) 4.058091286307054\n",
      "Aladdin (1992) 3.8127853881278537\n",
      "Mary Poppins (1964) 3.7247191011235956\n",
      "Father of the Bride Part II (1995) 2.8984375\n",
      "Kolya (1996) 3.9914529914529915\n",
      "Romy and Michele's High School Reunion (1997) 3.061224489795918\n",
      "Cool Runnings (1993) 3.161764705882353\n",
      "To Wong Foo, Thanks for Everything! Julie Newmar (1995) 2.8947368421052633\n",
      "Sleepless in Seattle (1993) 3.539906103286385\n",
      "Bio-Dome (1996) 1.903225806451613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emma/anaconda3/lib/python3.6/site-packages/scipy/spatial/distance.py:720: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    }
   ],
   "source": [
    "# Code from M. Hendra Herviawan\n",
    "# https://hendra-herviawan.github.io/Movie-Recommendation-based-on-KNN-K-Nearest-Neighbors.html\n",
    "# Comments by me\n",
    "\n",
    "K = 10 # 10 neighbors\n",
    "avgRatingTS = 0 # start this variable at zero\n",
    "\n",
    "print(movieDict[1], '\\n') # Print the movie infomation using movie ID\n",
    "neighbors = getNeighbors(1, K) # Get 10 neighbors for Toy Story (1995) \n",
    "for neighbor in neighbors:\n",
    "    avgRatingTS += movieDict[neighbor][3]\n",
    "    # Add the rating of the item to avgRatingTS each iteration\n",
    "    print (movieDict[neighbor][0] + \" \" + str(movieDict[neighbor][3]))\n",
    "    # Print the title, plus a space, plus the rating from movieDict\n",
    "\n",
    "avgRatingTS /= K # Update avgRatingTS to be divided by K (10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top ten related movies, according to this approach, are listed above. Some of them seem reasonable, some are not. The top movie is The Sting. I looked this movie up and have included a brief summary below, taken from [this Wikipedia article](https://en.wikipedia.org/wiki/The_Sting):\n",
    ">The Sting is a 1973 American caper film set in September 1936, involving a complicated plot by two professional grifters (Paul Newman and Robert Redford) to con a mob boss (Robert Shaw)\n",
    "\n",
    "This film is not at all like Toy Story in plot, but they share enough other traits that it was recommended. This is a good example of code doing what you tell it to do, but not what you want it to do. Of course, some of the suggestions are reasonable, such as Aladdin and Mary Poppins.\n",
    "\n",
    "Of note is the fact that in Herviawan's tutorial an almost completely different list was generated. The only common feature is Aladdin, which is the second nearest neighbor in both. Herviawan's result was:\n",
    "* Liar Liar (1997) 3.15670103093\n",
    "* Aladdin (1992) 3.81278538813\n",
    "* Willy Wonka and the Chocolate Factory (1971) 3.63190184049\n",
    "* Monty Python and the Holy Grail (1974) 4.0664556962\n",
    "* Full Monty, The (1997) 3.92698412698\n",
    "* George of the Jungle (1997) 2.68518518519\n",
    "* Beavis and Butt-head Do America (1996) 2.78846153846\n",
    "* Birdcage, The (1996) 3.44368600683\n",
    "* Home Alone (1990) 3.08759124088\n",
    "* Aladdin and the King of Thieves (1996) 2.84615384615\n",
    "\n",
    "It appears that removing the less common genres had a big effect on the recommendation.\n",
    "\n",
    "\n",
    "Next, I will continue to follow the tutorial's example and compare the average rating I computed for the 10 neighbors as well as the actual film's overall average rating. Comparing the two ratings will help me evaluate the performance of the KNN implementation. In the tutorial, the average rating of the neighbors was ~3.3446."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.304634421453303"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avgRatingTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the list of movies was very different, the average rating only differs by about 0.04 points. For comparison, the average rating of the film is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8783185840707963"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieDict[1][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference is by ~0.57 points. Not too bad, but not outstanding.\n",
    "\n",
    "I am going to repeat this process for Men in Black. This is a fresh example. Recall, Toy Story and Men in Black were moderately different in my reading of the ComputeDistance() function's output. The number was ~0.756. That said, I personally think the movies have some shared qualities. I am interested to see if there will be any overlap between the two lists of recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Men in Black (1997)', [1, 1, 1, 0, 0, 1, 0], 0.5189003436426117, 3.745874587458746) \n",
      "\n",
      "Star Trek: First Contact (1996) 3.66027397260274\n",
      "Mission: Impossible (1996) 3.313953488372093\n",
      "Batman Returns (1992) 2.683098591549296\n",
      "True Lies (1994) 3.5625\n",
      "Terminator, The (1984) 3.9335548172757475\n",
      "Twister (1996) 3.2150170648464163\n",
      "Batman Forever (1995) 2.6666666666666665\n",
      "Jumanji (1995) 3.3125\n",
      "Evil Dead II (1987) 3.5168539325842696\n",
      "Abyss, The (1989) 3.589403973509934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emma/anaconda3/lib/python3.6/site-packages/scipy/spatial/distance.py:720: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    }
   ],
   "source": [
    "K= 10\n",
    "avgRatingMiB = 0\n",
    "\n",
    "print(movieDict[257], '\\n')\n",
    "neighbors = getNeighbors(257, K) # Men in Black (1997)\n",
    "for neighbor in neighbors:\n",
    "    avgRatingMiB += movieDict[neighbor][3]\n",
    "    print (movieDict[neighbor][0] + \" \" + str(movieDict[neighbor][3]))\n",
    "\n",
    "avgRatingMiB /= K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no overlap, but the suggestions here are a lot more reasonable. The results here include other Sci-Fi movies, other Adventure movies, and other Action movies. Although Evil Dead II may sound out of place, it is actually not a bad recommendation for someone who likes Men in Black. Of course, I am biased because Evil Dead II is coincidentally my favorite movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.345382250740716"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avgRatingMiB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.745874587458746"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieDict[257][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, the numbers are a bit closer, off by 0.4 instead of about 0.57. I interpret this result to mean that the KNN implementation performed slightly better for Men in Black. This may have to do with Men in Black's relative abundance and/or to do with it being in more categories. With a relative abundance/popularity score of ~0.52, it's essentially right in the middle in terms of popularity. Toy Story was more prevalent, at ~0.77."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN for Classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Numpy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having used KNN for recommendations, I want to explore a second way to use the algorithm on this dataset. Instead of recommending movies, I am going to try to predict the genre of a movie based on the rating. This time, I am going to use the scikit-learn library's version of KNN. If it is easy to predict rating from genre, I would conclude that there is a strong link between the two. If it is not easy, I would conclude there is a weak link. I am curious about this because both were contributors to the recommendations provided above. The correlation chart I previously mentioned showed that all genres were significantly correlated, with Action/Adventure in the lead. Correlations within a dataset can be informative. They can also be a problem for machine learning with some approaches, as seen by Linear Regression's undoing in the presence of multicollinearity. Thankfully, this does not apply to KNN classification. Regardless, I seek more information about how genre and rating might correlate.\n",
    "\n",
    "First, I have to do some data preparation. I am going to build two numpy arrays, one with genres and one with rounded ratings (i.e. 1, 2, 3, 4, or 5 stars). Then I will output the first 10 items of each, in addition to the dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myGenres = np.array([movieDict[i][1] for i in movieDict.keys()])\n",
    "myRating = np.array([[round(movieDict[i][3])] for i in movieDict.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 1],\n",
       "       [0, 1, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myGenres[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1682, 7)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myGenres.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.],\n",
       "       [4.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [4.]])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRating[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1682, 1)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRating.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' \n",
    "The parameters for test size and random_state that are used\n",
    "here were copied from documentation.\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "The split is 25% testing, 75% training. \n",
    "The random_state is the seed, which is set for reproducibility.\n",
    "'''\n",
    "X_train, X_test, y_train, y_test = train_test_split(myRating, myGenres, test_size=0.25, random_state=333)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=10, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a reminder, the categories for genre are in this order: Action, Adventure, Comedy, Drama, Romance, Sci-Fi, and Thriller.\n",
    "\n",
    "I will generate predictions for 1, 2, 3, 4, and 5 stars. This was the purpose of rounding the ratings earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(knn.predict([[1.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(knn.predict([[2.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(knn.predict([[3.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(knn.predict([[4.]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(knn.predict([[5.]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only ratings that generated predictions were 1 star, 4 stars, and 5 stars, all of which predict comedy. Ratings of 2 and 3 suggest no genres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring the KNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having trained the KNN model on the training set, it's time to evaluate the model using the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21852731591448932"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean accuracy for the KNN model is 21.8%. This result indicates that there is not a strong link between rating and genre, at least not one detectable by a KNN approach. I would therefore conclude that genre and rating are not jointly influencing the recommendations, but instead are distinct influences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "My goal was to examine the recommendations and consider how the different features of the dataset might inform the recommendations.\n",
    "\n",
    "My major take aways from this analysis are:\n",
    "* The tutorial KNN implementation is fairly successful as is\n",
    "* The amount of genres used in the dataset has a larger influence on which movies are recommended than the ratings do\n",
    "* Rating and genre do not have a strong relationship"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
